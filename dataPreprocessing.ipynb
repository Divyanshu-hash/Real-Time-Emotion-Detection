{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f058613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcb80059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_rgb(img):\n",
    "    if img.ndim == 2:  # (H, W)\n",
    "        img = np.expand_dims(img, axis=-1)  # (H, W, 1)\n",
    "    if img.shape[-1] == 1:\n",
    "        img = np.repeat(img, 3, axis=-1)  # (H, W, 3)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65770223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Data generators\n",
    "train_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=5,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=to_rgb,\n",
    "    validation_split=0.3\n",
    ")\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    preprocessing_function=to_rgb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a91d9da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20099 images belonging to 7 classes.\n",
      "Found 8610 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = train_gen.flow_from_directory(\n",
    "    'train',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_data = train_gen.flow_from_directory(\n",
    "    'train',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "    'test',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df46b153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Early stopping callback\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.0001,\n",
    "    patience=20,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    restore_best_weights=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd1823e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Compute class weights\n",
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_data.classes),\n",
    "    y=train_data.classes\n",
    ")\n",
    "class_weights_dict = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "157ade95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m578s\u001b[0m 913ms/step - accuracy: 0.1661 - loss: 2.1091 - val_accuracy: 0.2401 - val_loss: 2.0281\n",
      "Epoch 2/15\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m978s\u001b[0m 2s/step - accuracy: 0.2183 - loss: 2.0107 - val_accuracy: 0.3134 - val_loss: 1.9294\n",
      "Epoch 3/15\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m620s\u001b[0m 986ms/step - accuracy: 0.2657 - loss: 1.9408 - val_accuracy: 0.3383 - val_loss: 1.8752\n",
      "Epoch 4/15\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1106s\u001b[0m 2s/step - accuracy: 0.2940 - loss: 1.8883 - val_accuracy: 0.3269 - val_loss: 1.8471\n",
      "Epoch 5/15\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1297s\u001b[0m 2s/step - accuracy: 0.3030 - loss: 1.8542 - val_accuracy: 0.3574 - val_loss: 1.7850\n",
      "Epoch 6/15\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 708ms/step - accuracy: 0.3171 - loss: 1.8211 - val_accuracy: 0.3519 - val_loss: 1.7760\n",
      "Epoch 7/15\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 709ms/step - accuracy: 0.3325 - loss: 1.7956 - val_accuracy: 0.3287 - val_loss: 1.8019\n",
      "Epoch 8/15\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 702ms/step - accuracy: 0.3427 - loss: 1.7694 - val_accuracy: 0.3821 - val_loss: 1.7169\n",
      "Epoch 9/15\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m448s\u001b[0m 712ms/step - accuracy: 0.3472 - loss: 1.7528 - val_accuracy: 0.3890 - val_loss: 1.6938\n",
      "Epoch 10/15\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 709ms/step - accuracy: 0.3581 - loss: 1.7226 - val_accuracy: 0.3842 - val_loss: 1.6829\n",
      "Epoch 11/15\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m448s\u001b[0m 712ms/step - accuracy: 0.3604 - loss: 1.7051 - val_accuracy: 0.4031 - val_loss: 1.6576\n",
      "Epoch 12/15\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m444s\u001b[0m 706ms/step - accuracy: 0.3682 - loss: 1.6909 - val_accuracy: 0.3778 - val_loss: 1.6875\n",
      "Epoch 13/15\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m448s\u001b[0m 713ms/step - accuracy: 0.3741 - loss: 1.6727 - val_accuracy: 0.4172 - val_loss: 1.6173\n",
      "Epoch 14/15\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 704ms/step - accuracy: 0.3781 - loss: 1.6610 - val_accuracy: 0.4086 - val_loss: 1.6334\n",
      "Epoch 15/15\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m395s\u001b[0m 628ms/step - accuracy: 0.3827 - loss: 1.6576 - val_accuracy: 0.4253 - val_loss: 1.5907\n"
     ]
    }
   ],
   "source": [
    "# 7. Build MobileNetV2 model\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load base model\n",
    "base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "base_model.trainable = False  # Freeze base model\n",
    "\n",
    "# Add classifier head\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "output = Dense(train_data.num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 8. Train the head\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=15,\n",
    "    callbacks=[callback],\n",
    "    class_weight=class_weights_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "375175d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('Not_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4a8e924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m497s\u001b[0m 777ms/step - accuracy: 0.3814 - loss: 1.6588 - val_accuracy: 0.4089 - val_loss: 1.6172\n",
      "Epoch 2/30\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m488s\u001b[0m 775ms/step - accuracy: 0.4074 - loss: 1.5965 - val_accuracy: 0.4235 - val_loss: 1.5668\n",
      "Epoch 3/30\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m489s\u001b[0m 778ms/step - accuracy: 0.4330 - loss: 1.5430 - val_accuracy: 0.4534 - val_loss: 1.5254\n",
      "Epoch 4/30\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m487s\u001b[0m 775ms/step - accuracy: 0.4415 - loss: 1.5042 - val_accuracy: 0.4733 - val_loss: 1.4704\n",
      "Epoch 5/30\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m487s\u001b[0m 775ms/step - accuracy: 0.4624 - loss: 1.4626 - val_accuracy: 0.4728 - val_loss: 1.4587\n",
      "Epoch 6/30\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m686s\u001b[0m 1s/step - accuracy: 0.4718 - loss: 1.4235 - val_accuracy: 0.4885 - val_loss: 1.4187\n",
      "Epoch 7/30\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m535s\u001b[0m 850ms/step - accuracy: 0.4819 - loss: 1.3953 - val_accuracy: 0.4997 - val_loss: 1.3898\n",
      "Epoch 8/30\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m489s\u001b[0m 778ms/step - accuracy: 0.4962 - loss: 1.3701 - val_accuracy: 0.5105 - val_loss: 1.3539\n",
      "Epoch 9/30\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m490s\u001b[0m 780ms/step - accuracy: 0.4947 - loss: 1.3487 - val_accuracy: 0.5128 - val_loss: 1.3698\n",
      "Epoch 10/30\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m491s\u001b[0m 781ms/step - accuracy: 0.5048 - loss: 1.3306 - val_accuracy: 0.5243 - val_loss: 1.3317\n",
      "Epoch 11/30\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m488s\u001b[0m 776ms/step - accuracy: 0.5129 - loss: 1.3062 - val_accuracy: 0.5259 - val_loss: 1.3349\n",
      "Epoch 12/30\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m488s\u001b[0m 776ms/step - accuracy: 0.5179 - loss: 1.2792 - val_accuracy: 0.5310 - val_loss: 1.3122\n",
      "Epoch 13/30\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m514s\u001b[0m 817ms/step - accuracy: 0.5226 - loss: 1.2615 - val_accuracy: 0.5413 - val_loss: 1.3028\n",
      "Epoch 14/30\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m567s\u001b[0m 902ms/step - accuracy: 0.5309 - loss: 1.2492 - val_accuracy: 0.5376 - val_loss: 1.2998\n",
      "Epoch 15/30\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m572s\u001b[0m 909ms/step - accuracy: 0.5390 - loss: 1.2152 - val_accuracy: 0.5381 - val_loss: 1.2846\n",
      "Epoch 16/30\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m575s\u001b[0m 914ms/step - accuracy: 0.5430 - loss: 1.2082 - val_accuracy: 0.5405 - val_loss: 1.2881\n",
      "Epoch 17/30\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m576s\u001b[0m 916ms/step - accuracy: 0.5509 - loss: 1.1958 - val_accuracy: 0.5505 - val_loss: 1.2687\n",
      "Epoch 18/30\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m572s\u001b[0m 910ms/step - accuracy: 0.5580 - loss: 1.1661 - val_accuracy: 0.5515 - val_loss: 1.2747\n",
      "Epoch 19/30\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m568s\u001b[0m 902ms/step - accuracy: 0.5551 - loss: 1.1695 - val_accuracy: 0.5494 - val_loss: 1.2878\n",
      "Epoch 20/30\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m548s\u001b[0m 872ms/step - accuracy: 0.5657 - loss: 1.1427 - val_accuracy: 0.5595 - val_loss: 1.2434\n",
      "Epoch 21/30\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m546s\u001b[0m 869ms/step - accuracy: 0.5702 - loss: 1.1291 - val_accuracy: 0.5635 - val_loss: 1.2337\n",
      "Epoch 22/30\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m544s\u001b[0m 866ms/step - accuracy: 0.5743 - loss: 1.1158 - val_accuracy: 0.5679 - val_loss: 1.2232\n",
      "Epoch 23/30\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m543s\u001b[0m 863ms/step - accuracy: 0.5790 - loss: 1.1066 - val_accuracy: 0.5668 - val_loss: 1.2317\n",
      "Epoch 24/30\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m546s\u001b[0m 868ms/step - accuracy: 0.5876 - loss: 1.0882 - val_accuracy: 0.5667 - val_loss: 1.2337\n",
      "Epoch 25/30\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m547s\u001b[0m 869ms/step - accuracy: 0.5875 - loss: 1.0814 - val_accuracy: 0.5794 - val_loss: 1.2083\n",
      "Epoch 26/30\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m544s\u001b[0m 865ms/step - accuracy: 0.5952 - loss: 1.0665 - val_accuracy: 0.5692 - val_loss: 1.2390\n",
      "Epoch 27/30\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m542s\u001b[0m 863ms/step - accuracy: 0.5981 - loss: 1.0496 - val_accuracy: 0.5739 - val_loss: 1.2093\n",
      "Epoch 28/30\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m492s\u001b[0m 781ms/step - accuracy: 0.5999 - loss: 1.0477 - val_accuracy: 0.5780 - val_loss: 1.2177\n",
      "Epoch 29/30\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m473s\u001b[0m 753ms/step - accuracy: 0.6057 - loss: 1.0427 - val_accuracy: 0.5776 - val_loss: 1.2209\n",
      "Epoch 30/30\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m482s\u001b[0m 766ms/step - accuracy: 0.6106 - loss: 1.0272 - val_accuracy: 0.5718 - val_loss: 1.2224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# 9. Fine-tuning\n",
    "fine_tune_at = 100  # Unfreeze last 100 layers\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "for layer in base_model.layers[fine_tune_at:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompile for fine-tuning\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train further\n",
    "fine_tune_history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=30,\n",
    "    callbacks=[callback],\n",
    "    class_weight=class_weights_dict\n",
    ")\n",
    "\n",
    "model.save('model_15_epocs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e278ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 575ms/step - accuracy: 0.5712 - loss: 1.2219\n",
      "Test Accuracy: 0.5711897611618042\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_data)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d47e28e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m517s\u001b[0m 805ms/step - accuracy: 0.6103 - loss: 1.0191 - val_accuracy: 0.5811 - val_loss: 1.2018\n",
      "Epoch 2/5\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m497s\u001b[0m 791ms/step - accuracy: 0.6119 - loss: 1.0126 - val_accuracy: 0.5875 - val_loss: 1.1814\n",
      "Epoch 3/5\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m494s\u001b[0m 786ms/step - accuracy: 0.6204 - loss: 1.0000 - val_accuracy: 0.5871 - val_loss: 1.1921\n",
      "Epoch 4/5\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m538s\u001b[0m 855ms/step - accuracy: 0.6231 - loss: 0.9864 - val_accuracy: 0.5841 - val_loss: 1.2020\n",
      "Epoch 5/5\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m607s\u001b[0m 964ms/step - accuracy: 0.6249 - loss: 0.9768 - val_accuracy: 0.5909 - val_loss: 1.1808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# 9. Fine-tuning\n",
    "fine_tune_at = 100  # Unfreeze last 100 layers\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "for layer in base_model.layers[fine_tune_at:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompile for fine-tuning\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train further\n",
    "fine_tune_history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=5,\n",
    "    callbacks=[callback],\n",
    "    class_weight=class_weights_dict\n",
    ")\n",
    "\n",
    "model.save('model_35_epocs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a2021227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 357ms/step - accuracy: 0.5848 - loss: 1.1935\n",
      "Test Accuracy: 0.5848425626754761\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_data)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e16db353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m484s\u001b[0m 759ms/step - accuracy: 0.6281 - loss: 0.9748 - val_accuracy: 0.5912 - val_loss: 1.1746\n",
      "Epoch 2/7\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m482s\u001b[0m 766ms/step - accuracy: 0.6345 - loss: 0.9666 - val_accuracy: 0.5884 - val_loss: 1.1763\n",
      "Epoch 3/7\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m479s\u001b[0m 762ms/step - accuracy: 0.6373 - loss: 0.9571 - val_accuracy: 0.5884 - val_loss: 1.1987\n",
      "Epoch 4/7\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m482s\u001b[0m 766ms/step - accuracy: 0.6421 - loss: 0.9456 - val_accuracy: 0.5890 - val_loss: 1.1868\n",
      "Epoch 5/7\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m477s\u001b[0m 758ms/step - accuracy: 0.6431 - loss: 0.9457 - val_accuracy: 0.5944 - val_loss: 1.1756\n",
      "Epoch 6/7\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m477s\u001b[0m 758ms/step - accuracy: 0.6512 - loss: 0.9293 - val_accuracy: 0.5999 - val_loss: 1.1766\n",
      "Epoch 7/7\n",
      "\u001b[1m629/629\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m652s\u001b[0m 1s/step - accuracy: 0.6503 - loss: 0.9245 - val_accuracy: 0.5965 - val_loss: 1.1764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 381ms/step - accuracy: 0.5904 - loss: 1.1991\n",
      "Test Accuracy: 0.5904151797294617\n"
     ]
    }
   ],
   "source": [
    "# 9. Fine-tuning\n",
    "fine_tune_at = 100  # Unfreeze last 100 layers\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "for layer in base_model.layers[fine_tune_at:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompile for fine-tuning\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train further\n",
    "fine_tune_history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=7,\n",
    "    callbacks=[callback],\n",
    "    class_weight=class_weights_dict\n",
    ")\n",
    "\n",
    "model.save('model_42_epocs.h5')\n",
    "\n",
    "loss, accuracy = model.evaluate(test_data)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d925b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "def predict_emotion(image_path, model, class_indices):\n",
    "    # 1. Load image\n",
    "    img = image.load_img(image_path, target_size=(224, 224), color_mode='rgb')\n",
    "\n",
    "    # 2. Convert to array\n",
    "    img_array = image.img_to_array(img)\n",
    "\n",
    "    # 3. Expand dimensions to match batch format\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # 4. Preprocess input for MobileNetV2\n",
    "    img_array = preprocess_input(img_array)\n",
    "\n",
    "    # 5. Predict\n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_class = np.argmax(predictions[0])\n",
    "\n",
    "    # 6. Map index to label\n",
    "    labels_map = {v: k for k, v in class_indices.items()}\n",
    "    return labels_map[predicted_class]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "62602cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n",
      "Predicted Emotion: surprise\n"
     ]
    }
   ],
   "source": [
    "image_path = r'train\\surprise\\Training_320784.jpg'\n",
    "prediction = predict_emotion(image_path, model, train_data.class_indices)\n",
    "print(\"Predicted Emotion:\", prediction)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
